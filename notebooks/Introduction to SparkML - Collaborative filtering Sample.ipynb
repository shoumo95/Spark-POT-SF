{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3 - Spark MLlib\n",
    "\n",
    "##### \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E\"\n",
    "-Tom M. Mitchell\n",
    "\n",
    "#### Machine Learning - the science of getting computers to act without being explicitly programmed\n",
    "\n",
    "MLlib is Sparkâ€™s machine learning (ML) library. Its goal is to make practical machine learning scalable and easy. It consists of common learning algorithms and utilities, including classification, regression, clustering, collaborative filtering (this example!), dimensionality reduction, as well as lower-level optimization primitives and higher-level pipeline APIs.\n",
    "\n",
    "It divides into two packages:\n",
    "- spark.mllib contains the original API built on top of RDDs.\n",
    "- spark.ml provides higher-level API built on top of DataFrames for constructing ML pipelines.\n",
    "\n",
    "\n",
    "Using spark.ml is recommended because with DataFrames the API is more versatile and flexible. But we will keep supporting spark.mllib along with the development of spark.ml. Users should be comfortable using spark.mllib features and expect more features coming.\n",
    "\n",
    "http://spark.apache.org/docs/latest/mllib-guide.html\n",
    "\n",
    "## Online Purchase Recommendations\n",
    "\n",
    "Learn how to create a recommendation engine using the Alternating Least Squares algorithm in Spark's machine learning library\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/bradenrc/Spark_POT/master/Modules/MachineLearning/Collaborative%20Filtering/ALS.png' width=\"70%\" height=\"70%\"></img>\n",
    "\n",
    "\n",
    "Workflow:\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/bradenrc/Spark_POT/master/Modules/MachineLearning/Collaborative%20Filtering/als_flow.png' width=\"70%\" height=\"70%\"></img>\n",
    "\n",
    "\n",
    "### The data\n",
    "\n",
    "This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.  The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n",
    "\n",
    "http://archive.ics.uci.edu/ml/datasets/Online+Retail\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/bradenrc/Spark_POT/master/Modules/MachineLearning/Collaborative%20Filtering/FullFile.png' width=\"80%\" height=\"80%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an RDD from the csv data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2016-06-28 16:13:45--  https://raw.githubusercontent.com/bradenrc/Spark_POT/master/Modules/MachineLearning/Collaborative%20Filtering/OnlineRetail.csv.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7483128 (7.1M) [application/octet-stream]\n",
      "Last-modified header missing -- time-stamps turned off.\n",
      "--2016-06-28 16:13:45--  https://raw.githubusercontent.com/bradenrc/Spark_POT/master/Modules/MachineLearning/Collaborative%20Filtering/OnlineRetail.csv.gz\n",
      "Reusing existing connection to raw.githubusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7483128 (7.1M) [application/octet-stream]\n",
      "Saving to: 'OnlineRetail.csv.gz'\n",
      "\n",
      "100%[======================================>] 7,483,128   40.7MB/s   in 0.2s   \n",
      "\n",
      "2016-06-28 16:13:45 (40.7 MB/s) - 'OnlineRetail.csv.gz' saved [7483128/7483128]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/bradenrc/Spark_POT/master/Modules/MachineLearning/Collaborative%20Filtering/OnlineRetail.csv.gz -N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put the csv into an RDD (at first, each row in the RDD is a string which correlates to a line in the csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country\n",
      "536365,85123A,WHITE HANGING HEART T-LIGHT HOLDER,6,12/1/10 8:26,2.55,17850,United Kingdom\n",
      "536365,71053,WHITE METAL LANTERN,6,12/1/10 8:26,3.39,17850,United Kingdom\n",
      "536365,84406B,CREAM CUPID HEARTS COAT HANGER,8,12/1/10 8:26,2.75,17850,United Kingdom\n",
      "536365,84029G,KNITTED UNION FLAG HOT WATER BOTTLE,6,12/1/10 8:26,3.39,17850,United Kingdom\n"
     ]
    }
   ],
   "source": [
    "loadRetailData = sc.textFile(\"OnlineRetail.csv.gz\")\n",
    "\n",
    "for row in loadRetailData.take(5):\n",
    "    print row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare and shape the data:  \"80% of a Data Scientists  job\"\n",
    "\n",
    "\n",
    "### First we will pull the CSV data into a format that is usable by\n",
    "#### - removing the header\n",
    "#### - splitting the rows\n",
    "#### - removing data that is not relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the header from the RDD and split the string in each row by comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'536365', u'85123A', u'WHITE HANGING HEART T-LIGHT HOLDER', u'6', u'12/1/10 8:26', u'2.55', u'17850', u'United Kingdom']\n",
      "[u'536365', u'71053', u'WHITE METAL LANTERN', u'6', u'12/1/10 8:26', u'3.39', u'17850', u'United Kingdom']\n",
      "[u'536365', u'84406B', u'CREAM CUPID HEARTS COAT HANGER', u'8', u'12/1/10 8:26', u'2.75', u'17850', u'United Kingdom']\n",
      "[u'536365', u'84029G', u'KNITTED UNION FLAG HOT WATER BOTTLE', u'6', u'12/1/10 8:26', u'3.39', u'17850', u'United Kingdom']\n",
      "[u'536365', u'84029E', u'RED WOOLLY HOTTIE WHITE HEART.', u'6', u'12/1/10 8:26', u'3.39', u'17850', u'United Kingdom']\n"
     ]
    }
   ],
   "source": [
    "header = loadRetailData.first()\n",
    "loadRetailData = loadRetailData.filter(lambda line: line != header).\\\n",
    "                            map(lambda l: l.split(\",\"))\n",
    "\n",
    "for row in loadRetailData.take(5):\n",
    "    print row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NOTE:  The original file at UCI's Machine Learning Repository has commas in the product description.  Those have been removed to expediate the lab.\n",
    "#### Only keep rows that have a purchase quantity of greater than 0, a customerID not equal to 0, and a non blank stock code after removing non-numeric characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "loadRetailData = loadRetailData.filter(lambda l: int(l[3]) > 0\\\n",
    "                                and len(re.sub(\"\\D\", \"\", l[1])) != 0 \\\n",
    "                                and len(l[6]) != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map each line to a row and create a data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- custId: long (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- inv: long (nullable = true)\n",
      " |-- invDate: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- quant: long (nullable = true)\n",
      " |-- stockCode: long (nullable = true)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>custId</th>\n",
       "      <th>description</th>\n",
       "      <th>inv</th>\n",
       "      <th>invDate</th>\n",
       "      <th>price</th>\n",
       "      <th>quant</th>\n",
       "      <th>stockCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>17850</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>536365</td>\n",
       "      <td>12/1/10 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>6</td>\n",
       "      <td>85123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>17850</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>536365</td>\n",
       "      <td>12/1/10 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>6</td>\n",
       "      <td>71053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  custId                         description     inv  \\\n",
       "0  United Kingdom   17850  WHITE HANGING HEART T-LIGHT HOLDER  536365   \n",
       "1  United Kingdom   17850                 WHITE METAL LANTERN  536365   \n",
       "\n",
       "        invDate  price  quant  stockCode  \n",
       "0  12/1/10 8:26   2.55      6      85123  \n",
       "1  12/1/10 8:26   3.39      6      71053  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext, Row\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#Convert each line to a Row.\n",
    "loadRetailData = loadRetailData.map(lambda l: Row(inv=int(l[0]),\\\n",
    "                                    stockCode=int(re.sub(\"\\D\", \"\", l[1])),\\\n",
    "                                    description=l[2],\\\n",
    "                                    quant=int(l[3]),\\\n",
    "                                    invDate=l[4],\\\n",
    "                                    price=float(l[5]),\\\n",
    "                                    custId=int(l[6]),\\\n",
    "                                    country=l[7]))\n",
    "\n",
    "# Infer the schema, and register the DataFrame as a table.\n",
    "retailDf = sqlContext.createDataFrame(loadRetailData)\n",
    "print retailDf.printSchema()\n",
    "\n",
    "retailDf.registerTempTable(\"retailPurchases\")\n",
    "sqlContext.sql(\"SELECT * FROM retailPurchases limit 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keep only the data we need (custId, stockCode, and rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    custId, stockCode, 1 as purch\n",
    "FROM \n",
    "    retailPurchases \n",
    "group \n",
    "    by custId, stockCode\"\"\"\n",
    "retailDf = sqlContext.sql(query)\n",
    "retailDf.registerTempTable(\"retailDf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custId</th>\n",
       "      <th>stockCode</th>\n",
       "      <th>purch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12838</td>\n",
       "      <td>22941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17968</td>\n",
       "      <td>22731</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16210</td>\n",
       "      <td>20977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17897</td>\n",
       "      <td>84558</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16552</td>\n",
       "      <td>85123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17905</td>\n",
       "      <td>21662</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13468</td>\n",
       "      <td>21231</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16274</td>\n",
       "      <td>21809</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13090</td>\n",
       "      <td>22617</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16186</td>\n",
       "      <td>22865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   custId  stockCode  purch\n",
       "0   12838      22941      1\n",
       "1   17968      22731      1\n",
       "2   16210      20977      1\n",
       "3   17897      84558      1\n",
       "4   16552      85123      1\n",
       "5   17905      21662      1\n",
       "6   13468      21231      1\n",
       "7   16274      21809      1\n",
       "8   13090      22617      1\n",
       "9   16186      22865      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"select * from retailDf limit 10\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly split the data into:\n",
    "#### - testing set (10% of the data)\n",
    "#### - cross validation set (10% of the data) \n",
    "#### - training set (80% of the data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDf count:  208116  example: \n",
      "Row(custId=17968, stockCode=22731, purch=1)\n",
      "Row(custId=17897, stockCode=84558, purch=1)\n",
      "\n",
      "cvDf count:  25869  example: \n",
      "Row(custId=12838, stockCode=22941, purch=1)\n",
      "Row(custId=13468, stockCode=21231, purch=1)\n",
      "\n",
      "testDf count:  26127  example: \n",
      "Row(custId=16210, stockCode=20977, purch=1)\n",
      "Row(custId=13090, stockCode=22617, purch=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDf, cvDf, trainDf = retailDf.randomSplit([.1,.1,.8],1)\n",
    "\n",
    "print \"trainDf count: \", trainDf.count(), \" example: \"\n",
    "for row in trainDf.take(2): print row\n",
    "print\n",
    "\n",
    "print \"cvDf count: \", cvDf.count(), \" example: \"\n",
    "for row in cvDf.take(2): print row\n",
    "print\n",
    "\n",
    "print \"testDf count: \", testDf.count(), \" example: \"\n",
    "for row in testDf.take(2): print row\n",
    "print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build recommendation models\n",
    "\n",
    "#### Use training DF to train a model with Alternating Least Squares \n",
    "Latent Factors / rank<br>\n",
    "The number of columns in the user-feature and product-feature matricies)<br>\n",
    "Iterations / maxIter<br>\n",
    "The number of factorization runs<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has been trained\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "arguments = {}\n",
    "arguments[\"rank\"] = 15\n",
    "arguments[\"maxIter\"] = 15\n",
    "arguments[\"userCol\"] = \"custId\"\n",
    "arguments[\"itemCol\"] = \"stockCode\"\n",
    "arguments[\"ratingCol\"] = \"purch\"\n",
    "arguments[\"implicitPrefs\"] = True\n",
    "\n",
    "als1 = ALS(**arguments)\n",
    "model1 = als1.fit(trainDf)\n",
    "\n",
    "print \"The model has been trained\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "Use the models to predict what the user will rate a certain item.  \n",
    "\n",
    "The closer our prediction of a customer purchasing a product is to 1 the better fit the model is.\n",
    "\n",
    "For example:<br>\n",
    "<b>Customer A</b> purchased stockCode item <b>20831</b>, if we have confidence of .9999 that the customer would purchase that product we are very accurate.\n",
    "\n",
    "#### Evaluate the model with the cross validation dataframe by using the transform function.\n",
    "\n",
    "Some of the users or purchases in the cross validation data may not have been in the training data.  \n",
    "Let's remove the ones that are not, this makes it easier to test the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Examples\n",
      "16384\n",
      "16385\n",
      "16386\n",
      "16387\n",
      "16389\n",
      "\n",
      "Stock Examples\n",
      "2\n",
      "90116\n",
      "21846\n",
      "90118\n",
      "90119\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import BooleanType\n",
    "counter = 4\n",
    "\n",
    "customers = set(trainDf.map(lambda line: line.custId).collect())\n",
    "print \"Customer Examples\"\n",
    "for i, x in enumerate(customers): \n",
    "    print x\n",
    "    if i == counter : break\n",
    "\n",
    "print\n",
    "\n",
    "stock = set(trainDf.map(lambda line: line.stockCode).collect())\n",
    "print \"Stock Examples\"\n",
    "for i, x in enumerate(stock): \n",
    "    print x\n",
    "    if i == counter : break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Filter:  25869\n",
      "Post-Filter:  25844\n"
     ]
    }
   ],
   "source": [
    "#filter out customers and stock codes that will be actionable (customer exists, item in stock)\n",
    "print \"Pre-Filter: \", cvDf.count()\n",
    "cvDf = cvDf.rdd.filter(lambda line: line.stockCode in stock and\\\n",
    "                                           line.custId in customers).toDF()\n",
    "print \"Post-Filter: \", cvDf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(custId=14286, stockCode=20831, purch=1, prediction=0.0679328441619873)\n",
      "Row(custId=13949, stockCode=20831, purch=1, prediction=0.06638696044683456)\n",
      "Row(custId=14730, stockCode=21031, purch=1, prediction=0.020719466730952263)\n",
      "Row(custId=13038, stockCode=21231, purch=1, prediction=0.151198610663414)\n",
      "Row(custId=15855, stockCode=21231, purch=1, prediction=0.048063118010759354)\n"
     ]
    }
   ],
   "source": [
    "#Build Predictions, this will return every Customer, Item and Prediciton of their Purchase of the combination\n",
    "\n",
    "predictions1 = model1.transform(cvDf)\n",
    "for row in predictions1.take(5):\n",
    "    print row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the model\n",
    "\n",
    "Use the model to predict items the user will be interested in.\n",
    "\n",
    "First, create a dataframe in which each row has the user id and an item id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21231 15544\n",
      "85231 15544\n",
      "22431 15544\n",
      "23231 15544\n",
      "22831 15544\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "stock15544 = set(trainDf.filter(trainDf['custId'] == 15544).map(lambda line: line.stockCode).collect())\n",
    "\n",
    "userItems = trainDf.select(\"stockCode\").distinct().\\\n",
    "            withColumn('custId', lit(15544)).\\\n",
    "            rdd.filter(lambda line: line.stockCode not in stock15544).toDF()\n",
    "\n",
    "for row in userItems.take(5):\n",
    "    print row.stockCode, row.custId"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 'transform' to rate the prediction of purchase for each product for this specific customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20831 15544 0.00470375129953\n",
      "21031 15544 0.0102273710072\n",
      "21231 15544 0.0580250695348\n",
      "21631 15544 -0.0257182512432\n",
      "22031 15544 0.0572351813316\n"
     ]
    }
   ],
   "source": [
    "userItems = model1.transform(userItems)\n",
    "\n",
    "for row in userItems.take(5):\n",
    "    print row.stockCode, row.custId, row.prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the top 5 recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stockCode</th>\n",
       "      <th>custId</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84997</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.597668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21213</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.578849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16161</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.518497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22138</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.505846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22090</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.491485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stockCode  custId  prediction\n",
       "0      84997   15544    0.597668\n",
       "1      21213   15544    0.578849\n",
       "2      16161   15544    0.518497\n",
       "3      22138   15544    0.505846\n",
       "4      22090   15544    0.491485"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userItems.registerTempTable(\"predictions\")\n",
    "query = \"select * from predictions order by prediction desc limit 5\"\n",
    "\n",
    "sqlContext.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a product Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stockItems = sqlContext.sql(\"select distinct stockCode, description from retailPurchases\")\n",
    "stockItems.registerTempTable(\"stockItems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This user seems to have purchased a lot of childrens gifts and some holiday items.  The recomendation engine we created suggested some items along these lines\n",
    "\n",
    "##### The ALS algorithm uses some randomness, so the recommendations yours produces may be different than these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stockCode</th>\n",
       "      <th>custId</th>\n",
       "      <th>prediction</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84997</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.597668</td>\n",
       "      <td>GREEN 3 PIECE POLKADOT CUTLERY SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>84997</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.597668</td>\n",
       "      <td>CHILDRENS CUTLERY RETROSPOT RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84997</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.597668</td>\n",
       "      <td>BLUE 3 PIECE POLKADOT CUTLERY SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84997</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.597668</td>\n",
       "      <td>CHILDRENS CUTLERY POLKADOT PINK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84997</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.597668</td>\n",
       "      <td>RED 3 PIECE RETROSPOT CUTLERY SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>84997</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.597668</td>\n",
       "      <td>PINK 3 PIECE POLKADOT CUTLERY SET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>84997</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.597668</td>\n",
       "      <td>CHILDRENS CUTLERY POLKADOT BLUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>84997</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.597668</td>\n",
       "      <td>CHILDRENS CUTLERY POLKADOT GREEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21213</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.578849</td>\n",
       "      <td>PACK OF 72 SKULL CAKE CASES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16161</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.518497</td>\n",
       "      <td>WRAP ENGLISH ROSE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stockCode  custId  prediction                         description\n",
       "0      84997   15544    0.597668  GREEN 3 PIECE POLKADOT CUTLERY SET\n",
       "1      84997   15544    0.597668    CHILDRENS CUTLERY RETROSPOT RED \n",
       "2      84997   15544    0.597668   BLUE 3 PIECE POLKADOT CUTLERY SET\n",
       "3      84997   15544    0.597668     CHILDRENS CUTLERY POLKADOT PINK\n",
       "4      84997   15544    0.597668   RED 3 PIECE RETROSPOT CUTLERY SET\n",
       "5      84997   15544    0.597668   PINK 3 PIECE POLKADOT CUTLERY SET\n",
       "6      84997   15544    0.597668     CHILDRENS CUTLERY POLKADOT BLUE\n",
       "7      84997   15544    0.597668   CHILDRENS CUTLERY POLKADOT GREEN \n",
       "8      21213   15544    0.578849         PACK OF 72 SKULL CAKE CASES\n",
       "9      16161   15544    0.518497                  WRAP ENGLISH ROSE "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show recomended items\n",
    "query = \"\"\"\n",
    "select \n",
    "    predictions.*,\n",
    "    stockItems.description\n",
    "from\n",
    "    predictions\n",
    "inner join stockItems on\n",
    "    predictions.stockCode = stockItems.stockCode\n",
    "order by predictions.prediction desc\n",
    "limit 10\n",
    "\"\"\"\n",
    "sqlContext.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Now we can refine the model and test for better accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "By changing the hyperparameters we can refine the model and test it for accuracy.<br><br>\n",
    "There are two hyperparameters we will change:<br>\n",
    "-<b>rank</b> is the number of latent factors in the model.<br>\n",
    "-<b>iterations</b> is the number of iterations to run.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "als1 = ALS(rank=3, maxIter=15,userCol=\"custId\",itemCol=\"stockCode\",ratingCol=\"purch\",implicitPrefs=True)\n",
    "model1 = als1.fit(trainDf)\n",
    "predictions1 = model1.transform(cvDf)\n",
    "\n",
    "als2 = ALS(rank=15, maxIter=3,userCol=\"custId\",itemCol=\"stockCode\",ratingCol=\"purch\",implicitPrefs=True)\n",
    "model2 = als2.fit(trainDf)\n",
    "predictions2 = model2.transform(cvDf)\n",
    "\n",
    "als3 = ALS(rank=15, maxIter=15,userCol=\"custId\",itemCol=\"stockCode\",ratingCol=\"purch\",implicitPrefs=True)\n",
    "model3 = als3.fit(trainDf)\n",
    "predictions3 = model3.transform(cvDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can incorporate our cross validation data and determine how close of a match we have from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "predictions1 = model1.transform(cvDf)\n",
    "predictions2 = model2.transform(cvDf)\n",
    "predictions3 = model3.transform(cvDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use Mean Squared Error to determine the accuracy. This is done by comparing the prection value to the actual purchase value in our data in cvDF.\n",
    "<br><br>\n",
    "Per Wikipedia: In statistics, the mean squared error (MSE) or mean squared deviation (MSD) of an estimator measures the average of the squares of the errors or deviations, that is, the difference between the estimator and what is estimated.\n",
    "<br><br>\n",
    "What we are looking for here is the lowest number as compared to the others. A perfect match, being 0, is not really possible but lower is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error = 0.7388 for our first model\n",
      "Mean squared error = 0.7003 for our second model\n",
      "Mean squared error = 0.6691 for our third model\n"
     ]
    }
   ],
   "source": [
    "meanSquaredError1 = predictions1.map(lambda line: (line.purch - line.prediction)**2).mean()\n",
    "meanSquaredError2 = predictions2.map(lambda line: (line.purch - line.prediction)**2).mean()\n",
    "meanSquaredError3 = predictions3.map(lambda line: (line.purch - line.prediction)**2).mean()\n",
    "    \n",
    "print 'Mean squared error = %.4f for our first model' % meanSquaredError1\n",
    "print 'Mean squared error = %.4f for our second model' % meanSquaredError2\n",
    "print 'Mean squared error = %.4f for our third model' % meanSquaredError3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have determined the best model, the third model in this case. We can compare that to the testDF and again take the Mean Squared Error.\n",
    "<br><br>\n",
    "The purpose of this is to make sure we are not over matched to the cvDF data. It could be that we match one subset of our date well and not another.\n",
    "The importance here is to look for a close match on the MSE value between csDF and testDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error = 0.6691 for our third model using cvDF\n",
      "Mean squared error = 0.6677 for our third (and best) model using testDF\n"
     ]
    }
   ],
   "source": [
    "filteredTestDf = testDf.rdd.filter(lambda line: line.stockCode in stock and\\\n",
    "                                              line.custId in customers).toDF()\n",
    "predictions4 = model3.transform(filteredTestDf)\n",
    "meanSquaredError4 = predictions4.map(lambda line: (line.purch - line.prediction)**2).mean()\n",
    "\n",
    "\n",
    "print 'Mean squared error = %.4f for our third model using cvDF' % meanSquaredError3\n",
    "print 'Mean squared error = %.4f for our third (and best) model using testDF' % meanSquaredError4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Citation\n",
    "Daqing Chen, Sai Liang Sain, and Kun Guo, Data mining for the online retail industry: A case study of RFM model-based customer segmentation using data mining, Journal of Database Marketing and Customer Strategy Management, Vol. 19, No. 3, pp. 197Ã¢â‚¬â€œ208, 2012 (Published online before print: 27 August 2012. doi: 10.1057/dbm.2012.17)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
